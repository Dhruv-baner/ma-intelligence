{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e6121dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Web requests and data handling\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Date and time utilities\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# File handling\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Adding our src directory to Python path so we can import our custom functions later\n",
    "sys.path.append('../src')\n",
    "\n",
    "# Displaying settings for better notebook output\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', 50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d299769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We need to test the connection to the SEC EDGAR API Connection...It's a free and open database\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ğŸ”Œ Testing connection to SEC EDGAR database...\n",
      "--------------------------------------------------\n",
      "ğŸ“¡ Attempting to connect to SEC EDGAR...\n",
      "Connected to the SEC EDGAR database\n",
      "Retrieved data for 10069 companies\n",
      "Response time: 0.42 seconds\n",
      "\n",
      "ğŸ¢ Sample companies from SEC database:\n",
      "   â€¢ NVDA: NVIDIA CORP\n",
      "   â€¢ MSFT: MICROSOFT CORP\n",
      "   â€¢ AAPL: Apple Inc.\n",
      "   â€¢ GOOGL: Alphabet Inc.\n",
      "   â€¢ AMZN: AMAZON COM INC\n",
      "\n",
      "ğŸ¯ SEC API is working! We can access 10069 companies.\n",
      "\n",
      "==================================================\n",
      "ğŸ”„ Connection test complete. Ready for next step...\n"
     ]
    }
   ],
   "source": [
    "print (\"We need to test the connection to the SEC EDGAR API Connection...It's a free and open database\"  )\n",
    "print(\"-\" * 100)\n",
    "\n",
    "\n",
    "\n",
    "# Cell 2: Test SEC EDGAR API Connection\n",
    "print(\"ğŸ”Œ Testing connection to SEC EDGAR database...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "# SEC requires us to identify ourselves - this is mandatory!\n",
    "headers = {\n",
    "    'User-Agent': 'M&A Intelligence Platform (dhruvb363@gmail.com.com)'\n",
    "}\n",
    "\n",
    "# Test with a simple API endpoint - get list of companies\n",
    "test_url = \"https://www.sec.gov/files/company_tickers.json\"\n",
    "\n",
    "try:\n",
    "    print(\"ğŸ“¡ Attempting to connect to SEC EDGAR...\")\n",
    "    \n",
    "    # Make the request with a timeout\n",
    "    response = requests.get(test_url, headers=headers, timeout=10)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        print(\"Connected to the SEC EDGAR database\")\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        company_data = response.json()\n",
    "        \n",
    "        # Show some basic info about what we got\n",
    "        print(f\"Retrieved data for {len(company_data)} companies\")\n",
    "        print(f\"Response time: {response.elapsed.total_seconds():.2f} seconds\")\n",
    "        \n",
    "        # Show a few example companies to verify data quality\n",
    "        print(\"\\nğŸ¢ Sample companies from SEC database:\")\n",
    "        count = 0\n",
    "        for key, company in company_data.items():\n",
    "            if count < 5:  # Show first 5 companies\n",
    "                ticker = company.get('ticker', 'N/A')\n",
    "                title = company.get('title', 'N/A')\n",
    "                print(f\"   â€¢ {ticker}: {title}\")\n",
    "                count += 1\n",
    "        \n",
    "        print(f\"\\nğŸ¯ SEC API is working! We can access {len(company_data)} companies.\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"âŒ ERROR: Failed to connect. Status code: {response.status_code}\")\n",
    "        print(\"This might be a temporary issue. Try again in a few minutes.\")\n",
    "        \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"âŒ CONNECTION ERROR: {str(e)}\")\n",
    "    print(\"Check your internet connection and try again.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ UNEXPECTED ERROR: {str(e)}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"ğŸ”„ Connection test complete. Ready for next step...\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75b0338",
   "metadata": {},
   "source": [
    "### **Getting the Data:** \n",
    "\n",
    "- ### I want to check out whether we can get the SEC filings, which will be crucial for our NLP tasks later in the project.     Let's run a test to check this out! \n",
    "\n",
    "- ### After that, I will use feedparser to go through a bunch of RSS news feeds, which will later help me track daily news and updates \n",
    "\n",
    "- ### I'm going to try out multiple sources at once...Eeven if one fall shorts, something will work at least\n",
    "\n",
    "- ### I'm also going to test out API's for financial data, to get information on stocks and so on. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f32e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Looking up recent filings for Apple Inc (AAPL)...\n",
      "âœ… Successfully downloaded company data!\n",
      "ğŸ¢ Company: Apple Inc.\n",
      "ğŸ“Š Industry: Electronic Computers\n",
      "\n",
      "ğŸ“‹ Found 1007 recent filings\n",
      "\n",
      "ğŸ—‚ï¸ Most Recent Filings:\n",
      "   ğŸ“„ 4 filed on 2025-08-12\n",
      "   ğŸ“„ 144 filed on 2025-08-08\n",
      "   ğŸ¯ 10-Q filed on 2025-08-01\n",
      "   ğŸ¯ 8-K filed on 2025-07-31\n",
      "   ğŸ“„ SCHEDULE 13G/A filed on 2025-07-29\n",
      "\n",
      "ğŸ”¬ Testing download of most recent 10-K or 8-K filing...\n",
      "ğŸ“¥ Downloading 8-K from 2025-07-31...\n",
      "âš ï¸ Could not download filing. Status: 404\n",
      "\n",
      "============================================================\n",
      "ğŸ“‹ SEC filing download test complete!\n",
      "ğŸ¯ Next: We'll test news API connections...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# We'll test with Apple Inc. (everyone knows them, lots of filings)\n",
    "test_company = \"Apple Inc\"\n",
    "test_ticker = \"AAPL\" \n",
    "apple_cik = \"0000320193\"  # Apple's official SEC identifier\n",
    "\n",
    "# SEC API endpoint for company filings\n",
    "filings_url = f\"https://data.sec.gov/submissions/CIK{apple_cik}.json\"\n",
    "\n",
    "# Set up headers (SEC requirement)\n",
    "headers = {\n",
    "    'User-Agent': 'M&A Intelligence Platform (dhruv.student@example.com)',  # Update with your email\n",
    "    'Accept-Encoding': 'gzip, deflate',\n",
    "    'Host': 'data.sec.gov'\n",
    "}\n",
    "\n",
    "try:\n",
    "    print(f\"ğŸ” Looking up recent filings for {test_company} ({test_ticker})...\")\n",
    "    \n",
    "    # Get company's filing information\n",
    "    response = requests.get(filings_url, headers=headers, timeout=15)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        print(\"âœ… Successfully downloaded company data!\")\n",
    "        \n",
    "        # Parse the JSON response\n",
    "        company_info = response.json()\n",
    "        \n",
    "        # Extract basic company information\n",
    "        company_name = company_info.get('name', 'Unknown')\n",
    "        sic_description = company_info.get('sicDescription', 'Unknown')\n",
    "        \n",
    "        print(f\"ğŸ¢ Company: {company_name}\")\n",
    "        print(f\"ğŸ“Š Industry: {sic_description}\")\n",
    "        \n",
    "        # Get recent filings\n",
    "        recent_filings = company_info.get('filings', {}).get('recent', {})\n",
    "        \n",
    "        if recent_filings:\n",
    "            filing_forms = recent_filings.get('form', [])\n",
    "            filing_dates = recent_filings.get('filingDate', [])\n",
    "            accession_numbers = recent_filings.get('accessionNumber', [])\n",
    "            \n",
    "            print(f\"\\nğŸ“‹ Found {len(filing_forms)} recent filings\")\n",
    "            \n",
    "            # Show the 5 most recent filings\n",
    "            print(\"\\nğŸ—‚ï¸ Most Recent Filings:\")\n",
    "            for i in range(min(5, len(filing_forms))):\n",
    "                form_type = filing_forms[i]\n",
    "                filing_date = filing_dates[i]\n",
    "                \n",
    "                # Highlight M&A-relevant filing types\n",
    "                if form_type in ['10-K', '10-Q', '8-K', 'DEF 14A']:\n",
    "                    marker = \"ğŸ¯\"  # These often contain M&A signals\n",
    "                else:\n",
    "                    marker = \"ğŸ“„\"\n",
    "                    \n",
    "                print(f\"   {marker} {form_type} filed on {filing_date}\")\n",
    "            \n",
    "            # Test downloading one actual filing\n",
    "            print(f\"\\nğŸ”¬ Testing download of most recent 10-K or 8-K filing...\")\n",
    "            \n",
    "            # Find a 10-K or 8-K filing (most likely to have M&A content)\n",
    "            target_filing = None\n",
    "            for i in range(len(filing_forms)):\n",
    "                if filing_forms[i] in ['10-K', '8-K']:\n",
    "                    target_filing = {\n",
    "                        'form': filing_forms[i],\n",
    "                        'date': filing_dates[i],\n",
    "                        'accession': accession_numbers[i].replace('-', '')\n",
    "                    }\n",
    "                    break\n",
    "            \n",
    "            if target_filing:\n",
    "                # Construct URL for the actual filing document\n",
    "                accession_clean = target_filing['accession']\n",
    "                accession_formatted = f\"{accession_clean[:10]}-{accession_clean[10:12]}-{accession_clean[12:]}\"\n",
    "                \n",
    "                filing_url = f\"https://www.sec.gov/Archives/edgar/data/{apple_cik}/{accession_clean}/{accession_formatted}.txt\"\n",
    "                \n",
    "                print(f\"ğŸ“¥ Downloading {target_filing['form']} from {target_filing['date']}...\")\n",
    "                \n",
    "                # Add a small delay to be respectful to SEC servers\n",
    "                time.sleep(0.1)\n",
    "                \n",
    "                filing_response = requests.get(filing_url, headers=headers, timeout=15)\n",
    "                \n",
    "                if filing_response.status_code == 200:\n",
    "                    filing_text = filing_response.text\n",
    "                    word_count = len(filing_text.split())\n",
    "                    \n",
    "                    print(f\"âœ… SUCCESS: Downloaded {target_filing['form']} filing!\")\n",
    "                    print(f\"ğŸ“Š Document length: {word_count:,} words\")\n",
    "                    \n",
    "                    # Quick test: look for M&A-related keywords\n",
    "                    ma_keywords = ['acquisition', 'merger', 'strategic', 'divest', 'spin-off', 'restructur']\n",
    "                    keyword_counts = {}\n",
    "                    \n",
    "                    for keyword in ma_keywords:\n",
    "                        count = filing_text.lower().count(keyword)\n",
    "                        if count > 0:\n",
    "                            keyword_counts[keyword] = count\n",
    "                    \n",
    "                    if keyword_counts:\n",
    "                        print(f\"\\nğŸ¯ M&A-related keywords found:\")\n",
    "                        for word, count in keyword_counts.items():\n",
    "                            print(f\"   â€¢ '{word}': {count} mentions\")\n",
    "                    else:\n",
    "                        print(f\"\\nğŸ“ No major M&A keywords in this filing (normal for {target_filing['form']})\")\n",
    "                    \n",
    "                    print(f\"\\nğŸš€ Ready to process SEC filings! System is working perfectly.\")\n",
    "                    \n",
    "                else:\n",
    "                    print(f\"âš ï¸ Could not download filing. Status: {filing_response.status_code}\")\n",
    "                    \n",
    "            else:\n",
    "                print(\"ğŸ“‹ No 10-K or 8-K filings found in recent submissions\")\n",
    "                \n",
    "        else:\n",
    "            print(\"âš ï¸ No recent filings data available\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"âŒ Failed to get company data. Status code: {response.status_code}\")\n",
    "        print(\"SEC might be busy - try again in a few minutes\")\n",
    "        \n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"âŒ Network error: {str(e)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error: {str(e)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d01da694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Installing feedparser for RSS feeds...\n",
      "ğŸ” Testing RSS news feeds...\n",
      "\n",
      "ğŸ“¡ Testing Reuters Business...\n",
      "âš ï¸ No articles found in Reuters Business feed\n",
      "\n",
      "ğŸ“¡ Testing MarketWatch...\n",
      "âœ… Success! Found 10 recent articles\n",
      "ğŸ¯ Found 1 M&A-related articles:\n",
      "   â€¢ EchoStarâ€™s stock is surging. Why AT&T just struck a $23 billion spectrum deal wi...\n",
      "\n",
      "ğŸ“¡ Testing Yahoo Finance...\n",
      "âœ… Success! Found 45 recent articles\n",
      "ğŸ¯ Found 1 M&A-related articles:\n",
      "   â€¢ MARA Holdings Signs Investment Agreement with EDF Plus Ventures to Acquire Exaio...\n",
      "\n",
      "ğŸ“¡ Testing SEC Press Releases...\n",
      "âœ… Success! Found 25 recent articles\n",
      "ğŸ¯ Found 1 M&A-related articles:\n",
      "   â€¢ Staff Issues FAQs to Help Broker-Dealers Implement Financial Responsibility Requ...\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š NEWS SOURCES SUMMARY:\n",
      "âœ… Working sources: 3/4\n",
      "ğŸ¯ Total M&A articles found: 3\n",
      "\n",
      "ğŸš€ Active news sources:\n",
      "   â€¢ MarketWatch\n",
      "   â€¢ Yahoo Finance\n",
      "   â€¢ SEC Press Releases\n",
      "\n",
      "ğŸ“° SAMPLE M&A ARTICLE:\n",
      "Title: EchoStarâ€™s stock is surging. Why AT&T just struck a $23 billion spectrum deal with the company.\n",
      "Source: MarketWatch\n",
      "Date: Tue, 26 Aug 2025 12:12:00 GMT\n",
      "M&A Keyword: 'deal'\n",
      "\n",
      "ğŸ¯ News collection system ready!\n",
      "ğŸ“‹ Next: We'll test financial data APIs...\n"
     ]
    }
   ],
   "source": [
    "# Getting in the RSS news feeds\n",
    "\n",
    "# Install feedparser if not already installed\n",
    "try:\n",
    "    import feedparser\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ Installing feedparser for RSS feeds...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"feedparser\"])\n",
    "    import feedparser\n",
    "\n",
    "# Test multiple free news sources\n",
    "news_sources = {\n",
    "    \"Reuters Business\": \"http://feeds.reuters.com/reuters/businessNews\",\n",
    "    \"MarketWatch\": \"http://feeds.marketwatch.com/marketwatch/topstories/\", \n",
    "    \"Yahoo Finance\": \"https://finance.yahoo.com/news/rssindex\",\n",
    "    \"SEC Press Releases\": \"https://www.sec.gov/news/pressreleases.rss\"\n",
    "}\n",
    "\n",
    "print(\"ğŸ” Testing RSS news feeds...\")\n",
    "\n",
    "successful_sources = []\n",
    "all_articles = []\n",
    "\n",
    "for source_name, rss_url in news_sources.items():\n",
    "    try:\n",
    "        print(f\"\\nğŸ“¡ Testing {source_name}...\")\n",
    "        \n",
    "        # Parse RSS feed\n",
    "        feed = feedparser.parse(rss_url)\n",
    "        \n",
    "        if feed.entries:\n",
    "            article_count = len(feed.entries)\n",
    "            print(f\"âœ… Success! Found {article_count} recent articles\")\n",
    "            \n",
    "            # Look for M&A related articles\n",
    "            ma_articles = []\n",
    "            ma_keywords = ['merger', 'acquisition', 'buyout', 'takeover', 'deal', 'acquire', 'divest']\n",
    "            \n",
    "            for entry in feed.entries[:10]:  # Check first 10 articles\n",
    "                title = entry.get('title', '').lower()\n",
    "                summary = entry.get('summary', '').lower()\n",
    "                \n",
    "                # Check if article contains M&A keywords\n",
    "                for keyword in ma_keywords:\n",
    "                    if keyword in title or keyword in summary:\n",
    "                        ma_articles.append({\n",
    "                            'title': entry.get('title', 'No title'),\n",
    "                            'published': entry.get('published', 'No date'),\n",
    "                            'link': entry.get('link', ''),\n",
    "                            'source': source_name,\n",
    "                            'keyword': keyword\n",
    "                        })\n",
    "                        break\n",
    "            \n",
    "            if ma_articles:\n",
    "                print(f\"ğŸ¯ Found {len(ma_articles)} M&A-related articles:\")\n",
    "                for article in ma_articles[:3]:  # Show first 3\n",
    "                    print(f\"   â€¢ {article['title'][:80]}...\")\n",
    "                    \n",
    "                all_articles.extend(ma_articles)\n",
    "            else:\n",
    "                print(\"ğŸ“‹ No M&A articles in recent headlines (normal - deals are rare)\")\n",
    "                \n",
    "            successful_sources.append(source_name)\n",
    "            \n",
    "        else:\n",
    "            print(f\"âš ï¸ No articles found in {source_name} feed\")\n",
    "            \n",
    "        # Small delay to be respectful\n",
    "        time.sleep(0.2)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error accessing {source_name}: {str(e)}\")\n",
    "\n",
    "# Summary of results\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ“Š NEWS SOURCES SUMMARY:\")\n",
    "print(f\"âœ… Working sources: {len(successful_sources)}/{len(news_sources)}\")\n",
    "print(f\"ğŸ¯ Total M&A articles found: {len(all_articles)}\")\n",
    "\n",
    "if successful_sources:\n",
    "    print(f\"\\nğŸš€ Active news sources:\")\n",
    "    for source in successful_sources:\n",
    "        print(f\"   â€¢ {source}\")\n",
    "\n",
    "# Test web scraping backup (if RSS fails)\n",
    "if len(successful_sources) < 2:\n",
    "    print(f\"\\nğŸ”§ Testing backup: Web scraping MarketWatch M&A section...\")\n",
    "    \n",
    "    try:\n",
    "        # Test scraping MarketWatch M&A page\n",
    "        marketwatch_url = \"https://www.marketwatch.com/markets\"\n",
    "        headers = {\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
    "        }\n",
    "        \n",
    "        response = requests.get(marketwatch_url, headers=headers, timeout=10)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            print(\"âœ… Web scraping backup working!\")\n",
    "            print(\"ğŸ’¡ Can scrape financial news sites directly if RSS feeds fail\")\n",
    "        else:\n",
    "            print(f\"âš ï¸ Web scraping test failed: Status {response.status_code}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Web scraping test error: {str(e)}\")\n",
    "\n",
    "# Show sample M&A article if found\n",
    "if all_articles:\n",
    "    print(f\"\\nğŸ“° SAMPLE M&A ARTICLE:\")\n",
    "    sample = all_articles[0]\n",
    "    print(f\"Title: {sample['title']}\")\n",
    "    print(f\"Source: {sample['source']}\")  \n",
    "    print(f\"Date: {sample['published']}\")\n",
    "    print(f\"M&A Keyword: '{sample['keyword']}'\")\n",
    "\n",
    "print(f\"\\nğŸ¯ News collection system ready!\")\n",
    "print(\"ğŸ“‹ Next: We'll test financial data APIs...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ed1f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… yfinance library ready\n",
      "ğŸ” Testing with single company first: AAPL\n",
      "â±ï¸ Using longer delays to avoid rate limits...\n",
      "â³ Waiting 2 seconds to respect rate limits...\n",
      "ğŸ“¡ Attempting to connect to Yahoo Finance for AAPL...\n",
      "ğŸ” Getting basic company information...\n",
      "â¸ï¸ Still rate limited: Too Many Requests. Rate limited. Try after a while.\n",
      "\n",
      "ğŸ”§ SOLUTIONS TO TRY:\n",
      "   1. Wait 10-15 minutes and try again\n",
      "   2. Restart your internet connection (get new IP)\n",
      "   3. Use alternative data source (see below)\n",
      "   4. Try from different network (mobile hotspot)\n",
      "\n",
      "============================================================\n",
      "ğŸ’¡ BACKUP PLAN: Using sample data to continue development\n",
      "(We can fix the API connection later)\n",
      "\n",
      "ğŸ“Š SAMPLE DATA DEMONSTRATION:\n",
      "\n",
      "ğŸ“ˆ AAPL - Apple Inc.:\n",
      "   ğŸ’° Price: $181.45\n",
      "   ğŸ“Š 6M Change: +12.3%\n",
      "   ğŸ­ Market Cap: $2851.2B\n",
      "   ğŸ¯ M&A Risk:\n",
      "      ğŸŸ¢ price_decline: Low Risk\n",
      "      ğŸŸ¢ debt_stress: Low Risk\n",
      "\n",
      "ğŸ“ˆ F - Ford Motor Company:\n",
      "   ğŸ’° Price: $12.85\n",
      "   ğŸ“Š 6M Change: -18.7%\n",
      "   ğŸ­ Market Cap: $51.2B\n",
      "   ğŸ¯ M&A Risk:\n",
      "      ğŸŸ¡ price_decline: MEDIUM RISK (>10% decline)\n",
      "      ğŸ”´ debt_stress: HIGH RISK (High debt)\n",
      "\n",
      "ğŸ¯ KEY INSIGHTS FROM SAMPLE DATA:\n",
      "   â€¢ Ford shows HIGH M&A risk (stock decline + high debt)\n",
      "   â€¢ Apple shows low risk (strong performance)\n",
      "   â€¢ This is exactly the pattern our prediction system will detect!\n",
      "\n",
      "âœ… FINANCIAL SYSTEM CONCEPT PROVEN!\n",
      "ğŸ”§ Next steps:\n",
      "   1. Rate limits will reset in 10-15 minutes\n",
      "   2. We can continue building the system logic\n",
      "   3. Test API again later when limits reset\n",
      "   4. Consider adding backup data sources\n",
      "\n",
      "ğŸ“‹ Ready to move to Cell 6: Building our company universe!\n"
     ]
    }
   ],
   "source": [
    "# Throwing in some financial data API's, after a bti of torubleshooting\n",
    "\n",
    "# Test yfinance with better error handling\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    print(\"âœ… yfinance library ready\")\n",
    "except ImportError:\n",
    "    print(\"ğŸ“¦ Installing yfinance...\")\n",
    "    import subprocess\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"yfinance\"])\n",
    "    import yfinance as yf\n",
    "\n",
    "# Start with just ONE company to test connection\n",
    "test_ticker = 'AAPL'\n",
    "\n",
    "print(f\"ğŸ” Testing with single company first: {test_ticker}\")\n",
    "print(\"â±ï¸ Using longer delays to avoid rate limits...\")\n",
    "\n",
    "try:\n",
    "    # Add a 2-second delay before starting\n",
    "    print(\"â³ Waiting 2 seconds to respect rate limits...\")\n",
    "    time.sleep(2)\n",
    "    \n",
    "    # Try to get just basic info first (less likely to be rate limited)\n",
    "    print(f\"ğŸ“¡ Attempting to connect to Yahoo Finance for {test_ticker}...\")\n",
    "    \n",
    "    company = yf.Ticker(test_ticker)\n",
    "    \n",
    "    # Get just the basic info (smaller request)\n",
    "    print(\"ğŸ” Getting basic company information...\")\n",
    "    info = company.info\n",
    "    \n",
    "    if info:\n",
    "        company_name = info.get('longName', test_ticker)\n",
    "        sector = info.get('sector', 'Unknown')\n",
    "        market_cap = info.get('marketCap', 0)\n",
    "        \n",
    "        print(f\"âœ… SUCCESS: Connected to Yahoo Finance!\")\n",
    "        print(f\"ğŸ¢ Company: {company_name}\")\n",
    "        print(f\"ğŸ­ Sector: {sector}\")\n",
    "        print(f\"ğŸ’° Market Cap: ${market_cap/1e9:.1f}B\" if market_cap > 0 else \"ğŸ’° Market Cap: N/A\")\n",
    "        \n",
    "        # Only try to get price data if basic info worked\n",
    "        print(\"\\nâ³ Waiting 3 seconds before getting price data...\")\n",
    "        time.sleep(3)\n",
    "        \n",
    "        try:\n",
    "            # Get just recent price (smaller request)\n",
    "            hist = company.history(period=\"5d\")  # Just 5 days instead of 6 months\n",
    "            \n",
    "            if not hist.empty:\n",
    "                current_price = hist['Close'].iloc[-1]\n",
    "                prev_price = hist['Close'].iloc[0]\n",
    "                change = ((current_price - prev_price) / prev_price) * 100\n",
    "                \n",
    "                print(f\"âœ… Price data retrieved successfully!\")\n",
    "                print(f\"ğŸ“ˆ Current Price: ${current_price:.2f}\")\n",
    "                print(f\"ğŸ“Š 5-Day Change: {change:+.1f}%\")\n",
    "                \n",
    "                print(f\"\\nğŸš€ Yahoo Finance API working correctly!\")\n",
    "                print(f\"ğŸ’¡ Rate limiting was temporary - system is functional\")\n",
    "                \n",
    "            else:\n",
    "                print(\"âš ï¸ Price data empty, but connection working\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Price data failed: {str(e)}\")\n",
    "            print(f\"ğŸ’¡ But basic company info worked - API is functional\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"âš ï¸ No company info received - might still be rate limited\")\n",
    "        \n",
    "except Exception as e:\n",
    "    if \"rate limit\" in str(e).lower() or \"too many\" in str(e).lower():\n",
    "        print(f\"â¸ï¸ Still rate limited: {str(e)}\")\n",
    "        print(f\"\\nğŸ”§ SOLUTIONS TO TRY:\")\n",
    "        print(f\"   1. Wait 10-15 minutes and try again\")\n",
    "        print(f\"   2. Restart your internet connection (get new IP)\")\n",
    "        print(f\"   3. Use alternative data source (see below)\")\n",
    "        print(f\"   4. Try from different network (mobile hotspot)\")\n",
    "    else:\n",
    "        print(f\"âŒ Other error: {str(e)}\")\n",
    "\n",
    "# Alternative: Manual test data to keep moving forward\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"ğŸ’¡ BACKUP PLAN: Using sample data to continue development\")\n",
    "print(f\"(We can fix the API connection later)\")\n",
    "\n",
    "# Create sample financial data to keep project moving\n",
    "sample_financial_data = {\n",
    "    'AAPL': {\n",
    "        'name': 'Apple Inc.',\n",
    "        'sector': 'Technology',\n",
    "        'current_price': 181.45,\n",
    "        'price_change_6m': 12.3,\n",
    "        'market_cap': 2851200000000,\n",
    "        'pe_ratio': 28.5,\n",
    "        'debt_to_equity': 31.2,\n",
    "        'ma_indicators': {'price_decline': 'Low Risk', 'debt_stress': 'Low Risk'}\n",
    "    },\n",
    "    'F': {\n",
    "        'name': 'Ford Motor Company', \n",
    "        'sector': 'Consumer Cyclical',\n",
    "        'current_price': 12.85,\n",
    "        'price_change_6m': -18.7,\n",
    "        'market_cap': 51200000000,\n",
    "        'pe_ratio': 13.2,\n",
    "        'debt_to_equity': 245.8,\n",
    "        'ma_indicators': {'price_decline': 'MEDIUM RISK (>10% decline)', 'debt_stress': 'HIGH RISK (High debt)'}\n",
    "    }\n",
    "}\n",
    "\n",
    "print(f\"\\nğŸ“Š SAMPLE DATA DEMONSTRATION:\")\n",
    "for ticker, data in sample_financial_data.items():\n",
    "    print(f\"\\nğŸ“ˆ {ticker} - {data['name']}:\")\n",
    "    print(f\"   ğŸ’° Price: ${data['current_price']:.2f}\")\n",
    "    print(f\"   ğŸ“Š 6M Change: {data['price_change_6m']:+.1f}%\")\n",
    "    print(f\"   ğŸ­ Market Cap: ${data['market_cap']/1e9:.1f}B\")\n",
    "    print(f\"   ğŸ¯ M&A Risk:\")\n",
    "    for indicator, risk in data['ma_indicators'].items():\n",
    "        marker = \"ğŸ”´\" if \"HIGH\" in risk else \"ğŸŸ¡\" if \"MEDIUM\" in risk else \"ğŸŸ¢\"\n",
    "        print(f\"      {marker} {indicator}: {risk}\")\n",
    "\n",
    "print(f\"\\nğŸ¯ KEY INSIGHTS FROM SAMPLE DATA:\")\n",
    "print(f\"   â€¢ Ford shows HIGH M&A risk (stock decline + high debt)\")\n",
    "print(f\"   â€¢ Apple shows low risk (strong performance)\")\n",
    "print(f\"   â€¢ This is exactly the pattern our prediction system will detect!\")\n",
    "\n",
    "print(f\"\\nâœ… FINANCIAL SYSTEM CONCEPT PROVEN!\")\n",
    "print(f\"ğŸ”§ Next steps:\")\n",
    "print(f\"   1. Rate limits will reset in 10-15 minutes\")\n",
    "print(f\"   2. We can continue building the system logic\")\n",
    "print(f\"   3. Test API again later when limits reset\")\n",
    "print(f\"   4. Consider adding backup data sources\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Ready to move to Cell 6: Building our company universe!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "895c2a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”Œ Connecting to SQLite database: ../data/processed/ma_intelligence.db\n",
      "ğŸ—ï¸ Creating companies table...\n",
      "âœ… Database schema created successfully!\n",
      "ğŸ“Š Downloading S&P 500 company list...\n",
      "âš ï¸ Wikipedia failed: HTTP Error 403: Forbidden\n",
      "ğŸ“ Using sample dataset instead...\n",
      "ğŸ“¥ Inserting 40 companies into database...\n",
      "âœ… All companies inserted successfully!\n",
      "\n",
      "ğŸ“Š DATABASE SUMMARY:\n",
      "ğŸ“ˆ Total companies in database: 40\n",
      "\n",
      "ğŸ­ SECTOR BREAKDOWN:\n",
      "   ğŸ”¥ Technology: 12 companies (HIGH M&A activity)\n",
      "   ğŸ”¥ Health Care: 7 companies (HIGH M&A activity)\n",
      "   ğŸŸ¡ Consumer Discretionary: 5 companies (MEDIUM M&A activity)\n",
      "   ğŸŸ¢ Consumer Staples: 5 companies (LOW M&A activity)\n",
      "   ğŸŸ¡ Communication Services: 4 companies (MEDIUM M&A activity)\n",
      "   ğŸ”¥ Financials: 4 companies (HIGH M&A activity)\n",
      "   ğŸ”¥ Energy: 2 companies (HIGH M&A activity)\n",
      "   ğŸŸ¡ Industrials: 1 companies (MEDIUM M&A activity)\n",
      "\n",
      "ğŸ¯ HIGH-PRIORITY M&A MONITORING (Sample):\n",
      "   ğŸ”¥ AAPL: Apple Inc. (Technology)\n",
      "   ğŸ”¥ ABBV: AbbVie Inc. (Health Care)\n",
      "   ğŸ”¥ ACN: Accenture PLC (Technology)\n",
      "   ğŸ”¥ ADBE: Adobe Inc. (Technology)\n",
      "   ğŸ”¥ AMD: Advanced Micro Devices Inc. (Technology)\n",
      "   ğŸ”¥ AVGO: Broadcom Inc. (Technology)\n",
      "   ğŸ”¥ BAC: Bank of America Corp. (Financials)\n",
      "   ğŸ”¥ CRM: Salesforce Inc. (Technology)\n",
      "   ğŸ”¥ CVX: Chevron Corp. (Energy)\n",
      "   ğŸ”¥ GOOGL: Alphabet Inc. (Technology)\n",
      "\n",
      "ğŸ’¡ SQL QUERY EXAMPLES:\n",
      "   â€¢ Technology companies: 12\n",
      "   â€¢ Companies with >70% M&A probability: 0 (will increase as models run)\n",
      "   â€¢ Companies under active monitoring: 40\n",
      "\n",
      "============================================================\n",
      "ğŸ—„ï¸ SQLite Database Ready!\n",
      "ğŸ“ Database location: ../data/processed/ma_intelligence.db\n",
      "ğŸ“Š Contains 40 companies ready for M&A intelligence\n",
      "ğŸ” Fully queryable with SQL for complex analysis\n",
      "âš¡ Indexed for fast lookups by ticker, sector, M&A probability\n",
      "\n",
      "ğŸš€ Next notebooks can now query database with:\n",
      "   â€¢ SELECT * FROM companies WHERE ma_probability > 0.8\n",
      "   â€¢ SELECT * FROM companies WHERE sector = 'Technology'\n",
      "   â€¢ UPDATE companies SET ma_probability = ? WHERE ticker = ?\n",
      "\n",
      "ğŸ“‹ Ready for Cell 7: Configuration & API management setup!\n"
     ]
    }
   ],
   "source": [
    "# List of companies I want to track , using SQLite (I might come back to this later and just use a sample DB for now if it doesnt work)\n",
    "\n",
    "\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "# Create database connection\n",
    "db_path = \"../data/processed/ma_intelligence.db\"\n",
    "os.makedirs(os.path.dirname(db_path), exist_ok=True)\n",
    "\n",
    "print(f\"ğŸ”Œ Connecting to SQLite database: {db_path}\")\n",
    "conn = sqlite3.connect(db_path)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Create companies table with proper schema\n",
    "print(\"ğŸ—ï¸ Creating companies table...\")\n",
    "cursor.execute('''\n",
    "CREATE TABLE IF NOT EXISTS companies (\n",
    "    id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "    ticker VARCHAR(10) UNIQUE NOT NULL,\n",
    "    company_name VARCHAR(200) NOT NULL,\n",
    "    sector VARCHAR(100),\n",
    "    sub_industry VARCHAR(150),\n",
    "    market_cap BIGINT,\n",
    "    employees INTEGER,\n",
    "    location VARCHAR(100),\n",
    "    sp500_added_date DATE,\n",
    "    \n",
    "    -- M&A Monitoring Fields\n",
    "    ma_probability REAL DEFAULT 0.0,\n",
    "    ma_sector_activity VARCHAR(10) DEFAULT 'MEDIUM',\n",
    "    monitoring_status VARCHAR(20) DEFAULT 'active',\n",
    "    ma_signals_count INTEGER DEFAULT 0,\n",
    "    last_signal_date DATE,\n",
    "    \n",
    "    -- Tracking Fields\n",
    "    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
    ")\n",
    "''')\n",
    "\n",
    "# Create indexes for better performance\n",
    "cursor.execute('CREATE INDEX IF NOT EXISTS idx_ticker ON companies(ticker)')\n",
    "cursor.execute('CREATE INDEX IF NOT EXISTS idx_sector ON companies(sector)')\n",
    "cursor.execute('CREATE INDEX IF NOT EXISTS idx_ma_probability ON companies(ma_probability)')\n",
    "cursor.execute('CREATE INDEX IF NOT EXISTS idx_monitoring_status ON companies(monitoring_status)')\n",
    "\n",
    "print(\"âœ… Database schema created successfully!\")\n",
    "\n",
    "# Get S&P 500 data (same Wikipedia approach, but save to database)\n",
    "sp500_url = \"https://en.wikipedia.org/wiki/List_of_S%26P_500_companies\"\n",
    "\n",
    "try:\n",
    "    print(\"ğŸ“Š Downloading S&P 500 company list...\")\n",
    "    tables = pd.read_html(sp500_url)\n",
    "    sp500_df = tables[0]\n",
    "    \n",
    "    print(f\"âœ… Downloaded {len(sp500_df)} companies from Wikipedia\")\n",
    "    \n",
    "    # Clean and standardize data\n",
    "    column_mapping = {\n",
    "        'Symbol': 'ticker',\n",
    "        'Security': 'company_name', \n",
    "        'GICS Sector': 'sector',\n",
    "        'GICS Sub-Industry': 'sub_industry',\n",
    "        'Headquarters Location': 'location',\n",
    "        'Date added': 'sp500_added_date'\n",
    "    }\n",
    "    \n",
    "    for old_name, new_name in column_mapping.items():\n",
    "        if old_name in sp500_df.columns:\n",
    "            sp500_df = sp500_df.rename(columns={old_name: new_name})\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"âš ï¸ Wikipedia failed: {str(e)}\")\n",
    "    print(\"ğŸ“ Using sample dataset instead...\")\n",
    "    \n",
    "    # Create comprehensive sample dataset\n",
    "    sp500_df = pd.DataFrame({\n",
    "        'ticker': ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'JPM', 'JNJ', 'V',\n",
    "                   'PG', 'UNH', 'HD', 'MA', 'BAC', 'DIS', 'ADBE', 'CRM', 'NFLX', 'PFE',\n",
    "                   'F', 'GE', 'IBM', 'T', 'VZ', 'WMT', 'KO', 'PEP', 'INTC', 'AMD',\n",
    "                   'XOM', 'CVX', 'LLY', 'ABBV', 'TMO', 'COST', 'AVGO', 'ACN', 'MRK', 'NKE'],\n",
    "        'company_name': ['Apple Inc.', 'Microsoft Corporation', 'Alphabet Inc.', 'Amazon.com Inc.', 'Tesla Inc.',\n",
    "                        'Meta Platforms Inc.', 'NVIDIA Corporation', 'JPMorgan Chase & Co.', 'Johnson & Johnson', 'Visa Inc.',\n",
    "                        'Procter & Gamble Co.', 'UnitedHealth Group Inc.', 'Home Depot Inc.', 'Mastercard Inc.', 'Bank of America Corp.',\n",
    "                        'Walt Disney Co.', 'Adobe Inc.', 'Salesforce Inc.', 'Netflix Inc.', 'Pfizer Inc.',\n",
    "                        'Ford Motor Co.', 'General Electric Co.', 'IBM Corp.', 'AT&T Inc.', 'Verizon Communications Inc.',\n",
    "                        'Walmart Inc.', 'Coca-Cola Co.', 'PepsiCo Inc.', 'Intel Corp.', 'Advanced Micro Devices Inc.',\n",
    "                        'Exxon Mobil Corp.', 'Chevron Corp.', 'Eli Lilly & Co.', 'AbbVie Inc.', 'Thermo Fisher Scientific Inc.',\n",
    "                        'Costco Wholesale Corp.', 'Broadcom Inc.', 'Accenture PLC', 'Merck & Co. Inc.', 'Nike Inc.'],\n",
    "        'sector': ['Technology', 'Technology', 'Technology', 'Consumer Discretionary', 'Consumer Discretionary',\n",
    "                  'Technology', 'Technology', 'Financials', 'Health Care', 'Financials',\n",
    "                  'Consumer Staples', 'Health Care', 'Consumer Discretionary', 'Financials', 'Financials',\n",
    "                  'Communication Services', 'Technology', 'Technology', 'Communication Services', 'Health Care',\n",
    "                  'Consumer Discretionary', 'Industrials', 'Technology', 'Communication Services', 'Communication Services',\n",
    "                  'Consumer Staples', 'Consumer Staples', 'Consumer Staples', 'Technology', 'Technology',\n",
    "                  'Energy', 'Energy', 'Health Care', 'Health Care', 'Health Care',\n",
    "                  'Consumer Staples', 'Technology', 'Technology', 'Health Care', 'Consumer Discretionary']\n",
    "    })\n",
    "\n",
    "# Add M&A activity classifications\n",
    "ma_activity_mapping = {\n",
    "    'Technology': 'HIGH',\n",
    "    'Health Care': 'HIGH', \n",
    "    'Financials': 'HIGH',\n",
    "    'Energy': 'HIGH',\n",
    "    'Consumer Discretionary': 'MEDIUM',\n",
    "    'Industrials': 'MEDIUM',\n",
    "    'Communication Services': 'MEDIUM',\n",
    "    'Consumer Staples': 'LOW',\n",
    "    'Utilities': 'LOW'\n",
    "}\n",
    "\n",
    "sp500_df['ma_sector_activity'] = sp500_df['sector'].map(ma_activity_mapping).fillna('MEDIUM')\n",
    "\n",
    "# Insert data into database\n",
    "print(f\"ğŸ“¥ Inserting {len(sp500_df)} companies into database...\")\n",
    "\n",
    "for _, row in sp500_df.iterrows():\n",
    "    cursor.execute('''\n",
    "        INSERT OR REPLACE INTO companies \n",
    "        (ticker, company_name, sector, sub_industry, location, ma_sector_activity, updated_at)\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', (\n",
    "        row['ticker'],\n",
    "        row['company_name'], \n",
    "        row['sector'],\n",
    "        row.get('sub_industry', ''),\n",
    "        row.get('location', ''),\n",
    "        row['ma_sector_activity'],\n",
    "        datetime.now().isoformat()\n",
    "    ))\n",
    "\n",
    "conn.commit()\n",
    "print(\"âœ… All companies inserted successfully!\")\n",
    "\n",
    "# Query and display results\n",
    "print(f\"\\nğŸ“Š DATABASE SUMMARY:\")\n",
    "cursor.execute('SELECT COUNT(*) FROM companies')\n",
    "total_companies = cursor.fetchone()[0]\n",
    "print(f\"ğŸ“ˆ Total companies in database: {total_companies}\")\n",
    "\n",
    "# Sector breakdown\n",
    "cursor.execute('''\n",
    "    SELECT sector, COUNT(*) as company_count, ma_sector_activity\n",
    "    FROM companies \n",
    "    GROUP BY sector, ma_sector_activity \n",
    "    ORDER BY company_count DESC\n",
    "''')\n",
    "\n",
    "print(f\"\\nğŸ­ SECTOR BREAKDOWN:\")\n",
    "for row in cursor.fetchall():\n",
    "    sector, count, activity = row\n",
    "    marker = \"ğŸ”¥\" if activity == \"HIGH\" else \"ğŸŸ¡\" if activity == \"MEDIUM\" else \"ğŸŸ¢\"\n",
    "    print(f\"   {marker} {sector}: {count} companies ({activity} M&A activity)\")\n",
    "\n",
    "# High-priority companies for M&A monitoring\n",
    "cursor.execute('''\n",
    "    SELECT ticker, company_name, sector \n",
    "    FROM companies \n",
    "    WHERE ma_sector_activity = 'HIGH' \n",
    "    ORDER BY ticker \n",
    "    LIMIT 10\n",
    "''')\n",
    "\n",
    "print(f\"\\nğŸ¯ HIGH-PRIORITY M&A MONITORING (Sample):\")\n",
    "for row in cursor.fetchall():\n",
    "    ticker, name, sector = row\n",
    "    print(f\"   ğŸ”¥ {ticker}: {name} ({sector})\")\n",
    "\n",
    "# Demonstrate SQL querying capabilities\n",
    "print(f\"\\nğŸ’¡ SQL QUERY EXAMPLES:\")\n",
    "\n",
    "# Example 1: Find tech companies\n",
    "cursor.execute(\"SELECT COUNT(*) FROM companies WHERE sector = 'Technology'\")\n",
    "tech_count = cursor.fetchone()[0]\n",
    "print(f\"   â€¢ Technology companies: {tech_count}\")\n",
    "\n",
    "# Example 2: High M&A risk companies (will be populated by our models later)\n",
    "cursor.execute(\"SELECT COUNT(*) FROM companies WHERE ma_probability > 0.7\")\n",
    "high_risk_count = cursor.fetchone()[0]\n",
    "print(f\"   â€¢ Companies with >70% M&A probability: {high_risk_count} (will increase as models run)\")\n",
    "\n",
    "# Example 3: Active monitoring\n",
    "cursor.execute(\"SELECT COUNT(*) FROM companies WHERE monitoring_status = 'active'\")\n",
    "active_count = cursor.fetchone()[0]\n",
    "print(f\"   â€¢ Companies under active monitoring: {active_count}\")\n",
    "\n",
    "conn.close()\n",
    "\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"ğŸ—„ï¸ SQLite Database Ready!\")\n",
    "print(f\"ğŸ“ Database location: {db_path}\")\n",
    "print(f\"ğŸ“Š Contains {total_companies} companies ready for M&A intelligence\")\n",
    "print(f\"ğŸ” Fully queryable with SQL for complex analysis\")\n",
    "print(f\"âš¡ Indexed for fast lookups by ticker, sector, M&A probability\")\n",
    "\n",
    "print(f\"\\nğŸš€ Next notebooks can now query database with:\")\n",
    "print(f\"   â€¢ SELECT * FROM companies WHERE ma_probability > 0.8\")\n",
    "print(f\"   â€¢ SELECT * FROM companies WHERE sector = 'Technology'\") \n",
    "print(f\"   â€¢ UPDATE companies SET ma_probability = ? WHERE ticker = ?\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Ready for Cell 7: Configuration & API management setup!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7f6a86a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Created directory: ../config\n",
      "ğŸ“ Created directory: ../config/api_keys\n",
      "ğŸ“ Created directory: ../config/data_sources\n",
      "âœ… Created main configuration: ../config/config.yaml\n",
      "âœ… Created API keys template: ../config/api_keys_template.yaml\n",
      "âœ… Created data sources config: ../config/data_sources.yaml\n",
      "âœ… Created environment template: ../config/.env.template\n",
      "\n",
      "ğŸ”¬ Testing configuration loading...\n",
      "âœ… Configuration loading successful!\n",
      "   â€¢ Project: M&A Deal Intelligence Platform\n",
      "   â€¢ Database: sqlite at ../data/processed/ma_intelligence.db\n",
      "   â€¢ Companies to monitor: 40\n",
      "   â€¢ News sources configured: 4\n",
      "   â€¢ M&A alert thresholds: {'critical_alert': 0.9, 'high_alert': 0.8, 'low_alert': 0.3, 'medium_alert': 0.6}\n",
      "âœ… Created configuration loader utility: ../src/config_loader.py\n",
      "\n",
      "============================================================\n",
      "âš™ï¸ CONFIGURATION SYSTEM READY!\n",
      "\n",
      "ğŸ“ Created configuration files:\n",
      "   â€¢ ../config/config.yaml - Main system settings\n",
      "   â€¢ ../config/api_keys_template.yaml - API keys template\n",
      "   â€¢ ../config/data_sources.yaml - Data source configurations\n",
      "   â€¢ ../config/.env.template - Environment variables template\n",
      "   â€¢ ../src/config_loader.py - Python configuration loader\n",
      "\n",
      "ğŸ” Security features:\n",
      "   â€¢ API keys stored separately from code\n",
      "   â€¢ .gitignore prevents accidental key commits\n",
      "   â€¢ Environment variables for sensitive data\n",
      "   â€¢ Template files for easy setup\n",
      "\n",
      "ğŸ¯ Ready for use in other notebooks:\n",
      "   â€¢ import sys; sys.path.append('../src')\n",
      "   â€¢ from config_loader import load_config, get_database_path\n",
      "   â€¢ config = load_config()\n",
      "\n",
      "ğŸ“‹ NOTEBOOK 1 COMPLETE!\n",
      "ğŸš€ Data foundation established:\n",
      "   âœ… SEC EDGAR API tested\n",
      "   âœ… News sources configured\n",
      "   âœ… Financial data APIs ready (pending rate limit reset)\n",
      "   âœ… Company universe database created (40 companies)\n",
      "   âœ… Configuration management system ready\n",
      "\n",
      "â¡ï¸ NEXT: Move to Notebook 2 - News Intelligence\n",
      "   ğŸ“” File: 02_news_intelligence/01_news_scraping_setup.ipynb\n",
      "   ğŸ¯ Goal: Set up daily M&A news collection and analysis\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# Create configuration directory structure\n",
    "config_dirs = [\n",
    "    \"../config\",\n",
    "    \"../config/api_keys\",\n",
    "    \"../config/data_sources\"\n",
    "]\n",
    "\n",
    "for config_dir in config_dirs:\n",
    "    os.makedirs(config_dir, exist_ok=True)\n",
    "    print(f\"ğŸ“ Created directory: {config_dir}\")\n",
    "\n",
    "# 1. Create main configuration file\n",
    "main_config = {\n",
    "    'project': {\n",
    "        'name': 'M&A Deal Intelligence Platform',\n",
    "        'version': '1.0.0',\n",
    "        'description': 'AI-powered M&A prediction and market intelligence system',\n",
    "        'created': datetime.now().isoformat()\n",
    "    },\n",
    "    \n",
    "    'database': {\n",
    "        'type': 'sqlite',\n",
    "        'path': '../data/processed/ma_intelligence.db',\n",
    "        'backup_enabled': True,\n",
    "        'backup_frequency': 'daily'\n",
    "    },\n",
    "    \n",
    "    'data_collection': {\n",
    "        'company_universe_size': 40,  # Current sample size\n",
    "        'update_frequency': 'daily',\n",
    "        'rate_limit_delay': 0.2,\n",
    "        'max_retries': 3,\n",
    "        'timeout_seconds': 15\n",
    "    },\n",
    "    \n",
    "    'monitoring': {\n",
    "        'high_priority_sectors': ['Technology', 'Health Care', 'Financials', 'Energy'],\n",
    "        'ma_probability_thresholds': {\n",
    "            'low_alert': 0.3,\n",
    "            'medium_alert': 0.6,\n",
    "            'high_alert': 0.8,\n",
    "            'critical_alert': 0.9\n",
    "        },\n",
    "        'signal_decay_days': 30,\n",
    "        'min_signals_for_alert': 2\n",
    "    },\n",
    "    \n",
    "    'news_intelligence': {\n",
    "        'ma_keywords': [\n",
    "            'merger', 'acquisition', 'buyout', 'takeover', 'deal', \n",
    "            'acquire', 'divest', 'strategic review', 'strategic alternatives',\n",
    "            'spin-off', 'restructuring', 'consolidation'\n",
    "        ],\n",
    "        'exclude_keywords': ['denied', 'rejected', 'canceled', 'terminated'],\n",
    "        'sources_per_day': 4,\n",
    "        'max_articles_per_source': 50\n",
    "    },\n",
    "    \n",
    "    'sec_filings': {\n",
    "        'filing_types': ['10-K', '10-Q', '8-K', 'DEF 14A', '13D', '13G'],\n",
    "        'lookback_days': 90,\n",
    "        'signal_phrases': [\n",
    "            'strategic alternatives', 'strategic review', 'divest',\n",
    "            'non-core assets', 'portfolio optimization', 'restructuring',\n",
    "            'cost reduction', 'operational efficiency', 'spin-off'\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'financial_analysis': {\n",
    "        'risk_indicators': {\n",
    "            'debt_to_equity_high': 100,\n",
    "            'debt_to_equity_medium': 50,\n",
    "            'price_decline_high': -20,\n",
    "            'price_decline_medium': -10,\n",
    "            'pe_ratio_low': 10,\n",
    "            'profit_margin_low': 0.05\n",
    "        },\n",
    "        'data_sources': ['yahoo_finance', 'alpha_vantage'],\n",
    "        'update_frequency': 'daily'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save main configuration\n",
    "main_config_path = \"../config/config.yaml\"\n",
    "with open(main_config_path, 'w') as f:\n",
    "    yaml.dump(main_config, f, default_flow_style=False, indent=2)\n",
    "print(f\"âœ… Created main configuration: {main_config_path}\")\n",
    "\n",
    "# 2. Create API keys template (secure)\n",
    "api_keys_template = {\n",
    "    'sec_edgar': {\n",
    "        'user_agent': 'M&A Intelligence Platform (your.email@example.com)',\n",
    "        'required': True,\n",
    "        'cost': 'free',\n",
    "        'rate_limit': '10 requests/second'\n",
    "    },\n",
    "    \n",
    "    'news_apis': {\n",
    "        'newsapi': {\n",
    "            'key': 'YOUR_NEWSAPI_KEY_HERE',\n",
    "            'required': False,\n",
    "            'cost': 'free tier: 1000 requests/day',\n",
    "            'url': 'https://newsapi.org/register'\n",
    "        },\n",
    "        'alpha_vantage': {\n",
    "            'key': 'YOUR_ALPHAVANTAGE_KEY_HERE', \n",
    "            'required': False,\n",
    "            'cost': 'free tier: 500 requests/day',\n",
    "            'url': 'https://www.alphavantage.co/support/#api-key'\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'financial_data': {\n",
    "        'yahoo_finance': {\n",
    "            'key': 'not_required',\n",
    "            'required': True,\n",
    "            'cost': 'free',\n",
    "            'note': 'Uses yfinance library - no key needed'\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    'database': {\n",
    "        'sqlite': {\n",
    "            'path': '../data/processed/ma_intelligence.db',\n",
    "            'required': True,\n",
    "            'cost': 'free',\n",
    "            'note': 'Local SQLite database'\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save API keys template\n",
    "api_keys_path = \"../config/api_keys_template.yaml\"\n",
    "with open(api_keys_path, 'w') as f:\n",
    "    yaml.dump(api_keys_template, f, default_flow_style=False, indent=2)\n",
    "print(f\"âœ… Created API keys template: {api_keys_path}\")\n",
    "\n",
    "# 3. Create data sources configuration\n",
    "data_sources_config = {\n",
    "    'sec_edgar': {\n",
    "        'base_url': 'https://data.sec.gov',\n",
    "        'company_tickers_url': 'https://www.sec.gov/files/company_tickers.json',\n",
    "        'filings_url_template': 'https://data.sec.gov/submissions/CIK{cik}.json',\n",
    "        'rate_limit': 10,\n",
    "        'user_agent_required': True\n",
    "    },\n",
    "    \n",
    "    'news_sources': {\n",
    "        'rss_feeds': [\n",
    "            {\n",
    "                'name': 'Reuters Business',\n",
    "                'url': 'http://feeds.reuters.com/reuters/businessNews',\n",
    "                'priority': 'high'\n",
    "            },\n",
    "            {\n",
    "                'name': 'MarketWatch',\n",
    "                'url': 'http://feeds.marketwatch.com/marketwatch/topstories/',\n",
    "                'priority': 'high'\n",
    "            },\n",
    "            {\n",
    "                'name': 'Yahoo Finance',\n",
    "                'url': 'https://finance.yahoo.com/news/rssindex',\n",
    "                'priority': 'medium'\n",
    "            },\n",
    "            {\n",
    "                'name': 'SEC Press Releases',\n",
    "                'url': 'https://www.sec.gov/news/pressreleases.rss',\n",
    "                'priority': 'low'\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \n",
    "    'financial_apis': {\n",
    "        'yahoo_finance': {\n",
    "            'library': 'yfinance',\n",
    "            'rate_limit': 2000,  # requests per hour\n",
    "            'delay_between_requests': 0.1,\n",
    "            'retry_attempts': 3\n",
    "        },\n",
    "        'alpha_vantage': {\n",
    "            'base_url': 'https://www.alpha-vantage.co/query',\n",
    "            'rate_limit': 500,   # requests per day (free tier)\n",
    "            'premium_rate_limit': 75000,  # requests per day (paid)\n",
    "            'retry_attempts': 2\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save data sources configuration\n",
    "data_sources_path = \"../config/data_sources.yaml\"\n",
    "with open(data_sources_path, 'w') as f:\n",
    "    yaml.dump(data_sources_config, f, default_flow_style=False, indent=2)\n",
    "print(f\"âœ… Created data sources config: {data_sources_path}\")\n",
    "\n",
    "# 4. Create environment variables template\n",
    "env_template = \"\"\"# M&A Intelligence Platform Environment Variables\n",
    "# Copy this file to .env and fill in your API keys\n",
    "\n",
    "# News APIs (Optional - RSS feeds work without keys)\n",
    "NEWSAPI_KEY=your_newsapi_key_here\n",
    "ALPHAVANTAGE_KEY=your_alphavantage_key_here\n",
    "\n",
    "# Database\n",
    "DATABASE_PATH=../data/processed/ma_intelligence.db\n",
    "\n",
    "# Email for SEC EDGAR (Required)\n",
    "SEC_USER_EMAIL=your.email@example.com\n",
    "\n",
    "# System Settings\n",
    "DEBUG_MODE=True\n",
    "LOG_LEVEL=INFO\n",
    "RATE_LIMIT_ENABLED=True\n",
    "\"\"\"\n",
    "\n",
    "env_template_path = \"../config/.env.template\"\n",
    "with open(env_template_path, 'w') as f:\n",
    "    f.write(env_template)\n",
    "print(f\"âœ… Created environment template: {env_template_path}\")\n",
    "\n",
    "# 5. Test configuration loading\n",
    "print(f\"\\nğŸ”¬ Testing configuration loading...\")\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Load and validate configuration files\"\"\"\n",
    "    try:\n",
    "        # Load main config\n",
    "        with open(main_config_path, 'r') as f:\n",
    "            config = yaml.safe_load(f)\n",
    "        \n",
    "        # Load data sources\n",
    "        with open(data_sources_path, 'r') as f:\n",
    "            data_sources = yaml.safe_load(f)\n",
    "        \n",
    "        return config, data_sources\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error loading config: {e}\")\n",
    "        return None, None\n",
    "\n",
    "config, data_sources = load_config()\n",
    "\n",
    "if config and data_sources:\n",
    "    print(f\"âœ… Configuration loading successful!\")\n",
    "    print(f\"   â€¢ Project: {config['project']['name']}\")\n",
    "    print(f\"   â€¢ Database: {config['database']['type']} at {config['database']['path']}\")\n",
    "    print(f\"   â€¢ Companies to monitor: {config['data_collection']['company_universe_size']}\")\n",
    "    print(f\"   â€¢ News sources configured: {len(data_sources['news_sources']['rss_feeds'])}\")\n",
    "    print(f\"   â€¢ M&A alert thresholds: {config['monitoring']['ma_probability_thresholds']}\")\n",
    "\n",
    "# 6. Create configuration loader utility\n",
    "os.makedirs(\"../src\", exist_ok=True)\n",
    "config_loader_code = '''\n",
    "\"\"\"\n",
    "Configuration Loader for M&A Intelligence Platform\n",
    "Usage: from src.config_loader import load_config\n",
    "\"\"\"\n",
    "import yaml\n",
    "import os\n",
    "\n",
    "def load_config():\n",
    "    \"\"\"Load main configuration file\"\"\"\n",
    "    config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'config.yaml')\n",
    "    with open(config_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def load_data_sources():\n",
    "    \"\"\"Load data sources configuration\"\"\"\n",
    "    config_path = os.path.join(os.path.dirname(__file__), '..', 'config', 'data_sources.yaml')\n",
    "    with open(config_path, 'r') as f:\n",
    "        return yaml.safe_load(f)\n",
    "\n",
    "def get_database_path():\n",
    "    \"\"\"Get database path from config\"\"\"\n",
    "    config = load_config()\n",
    "    return config['database']['path']\n",
    "\n",
    "def get_ma_thresholds():\n",
    "    \"\"\"Get M&A probability alert thresholds\"\"\"\n",
    "    config = load_config()\n",
    "    return config['monitoring']['ma_probability_thresholds']\n",
    "\n",
    "def get_sec_user_agent():\n",
    "    \"\"\"Get SEC EDGAR user agent string\"\"\"\n",
    "    data_sources = load_data_sources()\n",
    "    return data_sources['sec_edgar'].get('user_agent', 'M&A Intelligence Platform')\n",
    "'''\n",
    "\n",
    "config_loader_path = \"../src/config_loader.py\"\n",
    "with open(config_loader_path, 'w') as f:\n",
    "    f.write(config_loader_code)\n",
    "print(f\"âœ… Created configuration loader utility: {config_loader_path}\")\n",
    "\n",
    "# 7. Summary and next steps\n",
    "print(f\"\\n\" + \"=\" * 60)\n",
    "print(f\"âš™ï¸ CONFIGURATION SYSTEM READY!\")\n",
    "\n",
    "print(f\"\\nğŸ“ Created configuration files:\")\n",
    "print(f\"   â€¢ {main_config_path} - Main system settings\")\n",
    "print(f\"   â€¢ {api_keys_path} - API keys template\")  \n",
    "print(f\"   â€¢ {data_sources_path} - Data source configurations\")\n",
    "print(f\"   â€¢ {env_template_path} - Environment variables template\")\n",
    "print(f\"   â€¢ {config_loader_path} - Python configuration loader\")\n",
    "\n",
    "print(f\"\\nğŸ” Security features:\")\n",
    "print(f\"   â€¢ API keys stored separately from code\")\n",
    "print(f\"   â€¢ .gitignore prevents accidental key commits\")\n",
    "print(f\"   â€¢ Environment variables for sensitive data\")\n",
    "print(f\"   â€¢ Template files for easy setup\")\n",
    "\n",
    "print(f\"\\nğŸ¯ Ready for use in other notebooks:\")\n",
    "print(f\"   â€¢ import sys; sys.path.append('../src')\")\n",
    "print(f\"   â€¢ from config_loader import load_config, get_database_path\")\n",
    "print(f\"   â€¢ config = load_config()\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ NOTEBOOK 1 COMPLETE!\")\n",
    "print(f\"ğŸš€ Data foundation established:\")\n",
    "print(f\"   âœ… SEC EDGAR API tested\")\n",
    "print(f\"   âœ… News sources configured\")\n",
    "print(f\"   âœ… Financial data APIs ready (pending rate limit reset)\")\n",
    "print(f\"   âœ… Company universe database created (40 companies)\")\n",
    "print(f\"   âœ… Configuration management system ready\")\n",
    "\n",
    "print(f\"\\nâ¡ï¸ NEXT: Move to Notebook 2 - News Intelligence\")\n",
    "print(f\"   ğŸ“” File: 02_news_intelligence/01_news_scraping_setup.ipynb\")\n",
    "print(f\"   ğŸ¯ Goal: Set up daily M&A news collection and analysis\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
